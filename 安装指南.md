# **大模型常见依赖库的安装问题汇总**

## 安装前须知：

最好使用conda 创建虚拟环境,[使用方法](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html)

```
conda create -n venv_name python=3.10
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

创建后，使用 以下两天命令确保 当前使用的 pip是虚拟环境下的，不然有可能会造成冲突

```
which python
which pip 
python -m pip  #此命令是确保使用虚拟环境下的pip 
```

## transformers 安装

这个库比较好安装，它不依赖torch

## accelerate 安装

一般在加载模型是如果使用 device_map = "auto" 时会用到，这个库的作用是用来加速训练的，**在安装它之前最好先安装torch,不然也会自动下载最新torch版本**

## **torch 库安装**

安装[链接](https://pytorch.org/get-started/previous-versions/ "安装链接")，从torch2.0后，在安装时会自动安装nvidia runtime，避免用户手动安装 CUDA ToolKits和配置环境变量

如果需要自定义CUDA开发、某些第三方库依赖CUDA编译等情况需要额外安装[CUDA ToolKit](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=18.04&target_type=runfile_local)

*Note:我自己测试中发现，我在已经安装完CUDA ToolKits=11.8的情况下，直接使用命令，会自动下载cuda12的运行库，如下图。这种情况下也能正常运行，原因见下图*

```
pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 
```

![1730355909000](image/Requriment/1730355909000.png "torch 版本")

![1730345732662](image/Requriment/1730345732662.png "nvidia runtime")![1730356453772](image/Requriment/1730356453772.png)

[autoawq ](https://github.com/casper-hansen/AutoAWQ/releases)安装

量化库一般依赖当前cuda、torch版本以及GPU型号、[GPU计算能力](https://developer.nvidia.com/cuda-gpus#compute)，这里推荐两种安装方式

1. 使用源码编译安装，在安装时需要修改setup.py 里依赖，不然有可能会自动下载最新的torch
2. 第二种 下载whl文件[这里](https://github.com/casper-hansen/AutoAWQ/releases)，whl文件是根据特定版本编译好的，应的版本安装就行，如果whl依赖别的库，可以使用事先安装好，在使用命令
3. 可以看到我这里是安装的autoawq是基于cuda11.8编译的,也能够正常运行，原因见下图

```
pip install --no-deps ./autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl  #安装时不下载依赖库
```

![1730357238054](image/Requriment/1730357238054.png)

## [flash-atten2](https://github.com/Dao-AILab/flash-attention/releases) 安装

如果上下文（Token）很长的话，QK计算会呈平方式增长，f为了加速QKV计算的算法，主要原理是通过某种方式将本来在VRAM（显存）挪到更快SRAM中计算，安装时需要事先安装CUDA ToolKit，安装方式如下参看repo

## [AutoGPTQ ](https://github.com/AutoGPTQ/AutoGPTQ/blob/main/docs/INSTALLATION.md)安装

使用以下命令安装，此版本auto-gptq是基于cuda12.1（我的cuda toolkit=11.8）正常运行

```
pip install auto-gptq==0.6.0
```
